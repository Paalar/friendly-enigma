{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "473596b5",
   "metadata": {},
   "source": [
    "# Statistikk fra de ulike eksperimentene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b38b5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc81144",
   "metadata": {},
   "source": [
    "## Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63faea2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-test:  Ttest_indResult(statistic=-1.0180293907272238, pvalue=0.3221530748941993)\n",
      "Wilcoxon:  WilcoxonResult(statistic=20.0, pvalue=0.4921875)\n"
     ]
    }
   ],
   "source": [
    "from experiments_data import exp1\n",
    "ttest = stats.ttest_ind(exp1.stl_aurocs, exp1.mtl_aurocs)\n",
    "wilc = stats.wilcoxon(exp1.stl_aurocs, exp1.mtl_aurocs)\n",
    "print(\"T-test: \", ttest)\n",
    "print(\"Wilcoxon: \", wilc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ad89bc",
   "metadata": {},
   "source": [
    "Ettersom eksperimentet ikke ser på å sammenligne STL og MTL så gir ikke denne T-Testen noe særlig mening. Hvis vi skulle sammenlignet med noe i dette eksperimentet ville det vært at opp mot majority classen og sagt at vi måler sannsynligheten for at vi treffer så ofte som vi gjør. Sjekk Santi sin matte evt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d910d24f",
   "metadata": {},
   "source": [
    "## Experiment 3 (4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28505c2",
   "metadata": {},
   "source": [
    "Vi ønsker å se på hvorvidt MTL med kul loss kan brukes istedenfor vanlig, kjedelig loss.\n",
    "\n",
    "Hvis vi vil kan vi ha null-hypotese om at det ikke er noe forskjell mellom MTL-R og MTL-FE.\n",
    "En alternativ hypotese er at det er forskjell, men litt usikker på om du har to ulike alternativer:\n",
    "MTL-R bedre enn MTL-FE eller MTL-FE bedre enn MTL-R.\n",
    "Eller om det bare er én alternativ: forskjell.\n",
    "\n",
    "T-Testen her vil fortelle oss sannsynligheten for dataen er random generert eller noe annet med lik sannsynlighet har inntruffet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf1a8fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WilcoxonResult(statistic=8.0, pvalue=0.048828125)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from experiments_data import exp4\n",
    "\n",
    "ttest3 = stats.ttest_ind(exp4.mtl_fe_aurocs, exp1.mtl_aurocs)\n",
    "pearson = stats.pearsonr(exp4.mtl_fe_aurocs, exp1.mtl_aurocs)\n",
    "def avg(lst):\n",
    "    return sum(lst)/len(lst)\n",
    "\n",
    "stats.mannwhitneyu(exp1.mtl_aurocs, exp4.mtl_fe_aurocs)\n",
    "stats.wilcoxon(exp1.mtl_aurocs, exp4.mtl_fe_aurocs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d53a8ee",
   "metadata": {},
   "source": [
    "T-testen sier at ting ikke er tilfeldig uavhengig: Disse er ikke relaterbare.\n",
    "Pearson-koeffisienten sier at dataen er negativt relatert, men 30% sannsynlighet at det bare er random. Så er de egentlig enige i at det ting ikke henger sammen her? Altså at vi _må_ rejecte null-hypotesen om at de er relatert?\n",
    "\n",
    "#### NB!\n",
    "Og svaret er **JUPP!** Sannsynligvis fordi de har kjørt på helt ulike parametere, her må jo mtl fra exp1 kjøres på nytt, med samme parametere som mtl_fe!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229b7eab",
   "metadata": {},
   "source": [
    "## Experiment 4 (5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5043284a",
   "metadata": {},
   "source": [
    "Vi ønsker å se om MTL > STL på sparse data. Her _kunne_ man kanskje hatt en null-hypotese om at det ikke er noen forskjell. Den alternative hypotesen kan da være at MTL > STL på alt fra 0% noise til 49% noise. 50% vil de være tilnærmet like gode ettersom MTL sine fordeler utjevnes av ekstra støy. Igjen er spørsmålet om alternativ hypotese, hva hvis STL er bedre enn MTL?\n",
    "Er det kanskje bedre å bare drøfte?\n",
    "\n",
    "T-Testen vil allikevel fortelle oss hvor sikre vi er på dataen, som vi da kan diskutere `mean` av."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6d885ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 percentage\n",
      "[0.99, 0.99, 0.989, 0.989, 0.989, 0.989, 0.989, 0.989, 0.989, 0.988]\n",
      "[0.98, 0.979, 0.979, 0.978, 0.976, 0.979, 0.979, 0.978, 0.979, 0.978]\n",
      "ttest p  3.7883519922248783e-16\n",
      "MannwhitneyuResult(statistic=0.0, pvalue=9.133589555477501e-05)\n",
      "avg diff  0.010574495792388894\n",
      "WilcoxonResult(statistic=0.0, pvalue=0.001953125)\n",
      "5 percentage\n",
      "[0.997, 0.997, 0.997, 0.997, 0.997, 0.997, 0.997, 0.997, 0.997, 0.997]\n",
      "[0.992, 0.992, 0.994, 0.994, 0.995, 0.993, 0.995, 0.995, 0.993, 0.994]\n",
      "ttest p  4.404278729178303e-08\n",
      "MannwhitneyuResult(statistic=0.0, pvalue=9.133589555477501e-05)\n",
      "avg diff  0.003061264753341675\n",
      "WilcoxonResult(statistic=0.0, pvalue=0.001953125)\n",
      "10 percentage\n",
      "[0.997, 0.997, 0.997, 0.997, 0.997, 0.997, 0.997, 0.997, 0.997, 0.997]\n",
      "[0.998, 0.998, 0.998, 0.998, 0.998, 0.997, 0.998, 0.997, 0.998, 0.997]\n",
      "ttest p  0.0002309309557541889\n",
      "MannwhitneyuResult(statistic=7.0, pvalue=0.0006574723348566069)\n",
      "avg diff  0.0003843069076538974\n",
      "WilcoxonResult(statistic=0.0, pvalue=0.001953125)\n",
      "15 percentage\n",
      "[0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998, 0.998]\n",
      "[0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999]\n",
      "ttest p  6.236330602459952e-232\n",
      "MannwhitneyuResult(statistic=0.0, pvalue=9.133589555477501e-05)\n",
      "avg diff  0.0011435568332672785\n",
      "WilcoxonResult(statistic=0.0, pvalue=0.001953125)\n"
     ]
    }
   ],
   "source": [
    "from experiments_data import exp5\n",
    "\n",
    "exp5data = zip(exp5.stl_aurocs, exp5.mtl_aurocs)\n",
    "\n",
    "for index, (r, fe) in enumerate(exp5data):\n",
    "    print(f\"{index * 5} percentage\")\n",
    "    rounded_r = [round(val, 3) for val in r]\n",
    "    rounded_fe = [round(val, 3) for val in fe]\n",
    "    print(rounded_r)\n",
    "    print(rounded_fe)\n",
    "    ttest5 = stats.ttest_ind(rounded_r, rounded_fe)\n",
    "    print(\"ttest p \",ttest5.pvalue)\n",
    "    mannwhitney5 = stats.mannwhitneyu(r,fe)\n",
    "    print(mannwhitney5)\n",
    "    avg_difference = abs((sum(r)/len(r)) - (sum(fe)/len(r)))\n",
    "    print(\"avg diff \", avg_difference)\n",
    "    wilc5 = stats.wilcoxon(r, fe)\n",
    "    print(wilc5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6ce07f",
   "metadata": {},
   "source": [
    "## Experiment 5 (6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d13550",
   "metadata": {},
   "source": [
    "Her tester vi 5 og 10 prosent av dataen med 10% til 50% støy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6882b638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10% noise 5 size\n",
      "MannwhitneyuResult(statistic=0.0, pvalue=9.133589555477501e-05)\n",
      "WilcoxonResult(statistic=0.0, pvalue=0.001953125)\n",
      "20% noise 5 size\n",
      "MannwhitneyuResult(statistic=0.0, pvalue=9.133589555477501e-05)\n",
      "WilcoxonResult(statistic=0.0, pvalue=0.001953125)\n",
      "30% noise 5 size\n",
      "MannwhitneyuResult(statistic=0.0, pvalue=9.133589555477501e-05)\n",
      "WilcoxonResult(statistic=0.0, pvalue=0.001953125)\n",
      "40% noise 5 size\n",
      "MannwhitneyuResult(statistic=2.0, pvalue=0.00016491926038899677)\n",
      "WilcoxonResult(statistic=0.0, pvalue=0.001953125)\n",
      "50% noise 5 size\n",
      "MannwhitneyuResult(statistic=17.0, pvalue=0.007009638556979976)\n",
      "WilcoxonResult(statistic=3.0, pvalue=0.009765625)\n",
      "\n",
      "10% noise 10 size\n",
      "MannwhitneyuResult(statistic=0.0, pvalue=9.133589555477501e-05)\n",
      "WilcoxonResult(statistic=0.0, pvalue=0.001953125)\n",
      "20% noise 10 size\n",
      "MannwhitneyuResult(statistic=0.0, pvalue=9.133589555477501e-05)\n",
      "WilcoxonResult(statistic=0.0, pvalue=0.001953125)\n",
      "30% noise 10 size\n",
      "MannwhitneyuResult(statistic=0.0, pvalue=9.133589555477501e-05)\n",
      "WilcoxonResult(statistic=0.0, pvalue=0.001953125)\n",
      "40% noise 10 size\n",
      "MannwhitneyuResult(statistic=26.0, pvalue=0.03783078607194352)\n",
      "WilcoxonResult(statistic=6.0, pvalue=0.02734375)\n",
      "50% noise 10 size\n",
      "MannwhitneyuResult(statistic=70.0, pvalue=0.9393877484935417)\n",
      "WilcoxonResult(statistic=10.0, pvalue=0.083984375)\n"
     ]
    }
   ],
   "source": [
    "from experiments_data import exp6\n",
    "\n",
    "exp5data5size = zip(exp6.stl_5s, exp6.mtl_5s)\n",
    "exp5data10size = zip(exp6.stl_10s, exp6.mtl_10s)\n",
    "\n",
    "for index, (r, fe) in enumerate(exp5data5size):\n",
    "    print(f\"{index+1}0% noise 5 size\")\n",
    "    mann5 = stats.mannwhitneyu(r, fe)\n",
    "    print(mann5)\n",
    "    wilc6 = stats.wilcoxon(r, fe)\n",
    "    print(wilc6)\n",
    "    \n",
    "print()\n",
    "for index, (r, fe) in enumerate(exp5data10size):\n",
    "    print(f\"{index+1}0% noise 10 size\")\n",
    "    mann5 = stats.mannwhitneyu(r, fe, alternative=\"less\")\n",
    "    print(mann5)\n",
    "    wilc6 = stats.wilcoxon(r, fe)\n",
    "    print(wilc6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffafd9d",
   "metadata": {},
   "source": [
    "## Experiment 6 (7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b35e39c9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10% noise\n",
      "0.13968506006174902\n",
      "MannwhitneyuResult(statistic=35.0, pvalue=0.13651816987559418)\n",
      "WilcoxonResult(statistic=5.0, pvalue=0.01953125)\n",
      "20% noise\n",
      "0.5977760582488791\n",
      "MannwhitneyuResult(statistic=36.0, pvalue=0.15374472830934066)\n",
      "WilcoxonResult(statistic=20.0, pvalue=0.4921875)\n",
      "30% noise\n",
      "0.5017440509415498\n",
      "MannwhitneyuResult(statistic=40.0, pvalue=0.23633779675579358)\n",
      "WilcoxonResult(statistic=20.0, pvalue=0.4921875)\n",
      "40% noise\n",
      "0.9036138653761041\n",
      "MannwhitneyuResult(statistic=50.0, pvalue=0.4849249884965778)\n",
      "WilcoxonResult(statistic=25.0, pvalue=0.845703125)\n",
      "50% noise\n",
      "0.10352697524083414\n",
      "MannwhitneyuResult(statistic=34.0, pvalue=0.12066079650859002)\n",
      "WilcoxonResult(statistic=21.0, pvalue=0.556640625)\n"
     ]
    }
   ],
   "source": [
    "from experiments_data import exp7\n",
    "\n",
    "exp6data = zip(exp7.r_aurocs, exp7.fe_aurocs)\n",
    "\n",
    "for index, (r, fe) in enumerate(exp6data):\n",
    "    print(f\"{index+1}0% noise\")\n",
    "    ttest7 = stats.ttest_ind(r, fe)\n",
    "    print(ttest7.pvalue)\n",
    "    mann7 = stats.mannwhitneyu(r, fe)\n",
    "    print(mann7)\n",
    "    wilc7 = stats.wilcoxon(r, fe)\n",
    "    print(wilc7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d17788",
   "metadata": {},
   "source": [
    "Ingen av de kan rejecte null-hypotesen, altså er det sannsynlig at ting henger sammen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9225ea6d",
   "metadata": {},
   "source": [
    "## Fast DeLong from Yandex School of Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60d4647",
   "metadata": {},
   "source": [
    "According to this guide, https://glassboxmedicine.com/2020/02/04/comparing-aucs-of-machine-learning-models-with-delongs-test/, you can compare two AU(RO)C's through DeLong's test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e46244dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "\n",
    "# AUC comparison adapted from\n",
    "# https://github.com/Netflix/vmaf/\n",
    "def compute_midrank(x):\n",
    "    \"\"\"Computes midranks.\n",
    "    Args:\n",
    "       x - a 1D numpy array\n",
    "    Returns:\n",
    "       array of midranks\n",
    "    \"\"\"\n",
    "    J = np.argsort(x)\n",
    "    Z = x[J]\n",
    "    N = len(x)\n",
    "    T = np.zeros(N, dtype=np.float)\n",
    "    i = 0\n",
    "    while i < N:\n",
    "        j = i\n",
    "        while j < N and Z[j] == Z[i]:\n",
    "            j += 1\n",
    "        T[i:j] = 0.5*(i + j - 1)\n",
    "        i = j\n",
    "    T2 = np.empty(N, dtype=np.float)\n",
    "    # Note(kazeevn) +1 is due to Python using 0-based indexing\n",
    "    # instead of 1-based in the AUC formula in the paper\n",
    "    T2[J] = T + 1\n",
    "    return T2\n",
    "\n",
    "\n",
    "def fastDeLong(predictions_sorted_transposed, label_1_count):\n",
    "    \"\"\"\n",
    "    The fast version of DeLong's method for computing the covariance of\n",
    "    unadjusted AUC.\n",
    "    Args:\n",
    "       predictions_sorted_transposed: a 2D numpy.array[n_classifiers, n_examples]\n",
    "          sorted such as the examples with label \"1\" are first\n",
    "    Returns:\n",
    "       (AUC value, DeLong covariance)\n",
    "    Reference:\n",
    "     @article{sun2014fast,\n",
    "       title={Fast Implementation of DeLong's Algorithm for\n",
    "              Comparing the Areas Under Correlated Receiver Operating Characteristic Curves},\n",
    "       author={Xu Sun and Weichao Xu},\n",
    "       journal={IEEE Signal Processing Letters},\n",
    "       volume={21},\n",
    "       number={11},\n",
    "       pages={1389--1393},\n",
    "       year={2014},\n",
    "       publisher={IEEE}\n",
    "     }\n",
    "    \"\"\"\n",
    "    # Short variables are named as they are in the paper\n",
    "    m = label_1_count\n",
    "    n = predictions_sorted_transposed.shape[1] - m\n",
    "    positive_examples = predictions_sorted_transposed[:, :m]\n",
    "    negative_examples = predictions_sorted_transposed[:, m:]\n",
    "    k = predictions_sorted_transposed.shape[0]\n",
    "\n",
    "    tx = np.empty([k, m], dtype=np.float)\n",
    "    ty = np.empty([k, n], dtype=np.float)\n",
    "    tz = np.empty([k, m + n], dtype=np.float)\n",
    "    for r in range(k):\n",
    "        tx[r, :] = compute_midrank(positive_examples[r, :])\n",
    "        ty[r, :] = compute_midrank(negative_examples[r, :])\n",
    "        tz[r, :] = compute_midrank(predictions_sorted_transposed[r, :])\n",
    "    aucs = tz[:, :m].sum(axis=1) / m / n - float(m + 1.0) / 2.0 / n\n",
    "    v01 = (tz[:, :m] - tx[:, :]) / n\n",
    "    v10 = 1.0 - (tz[:, m:] - ty[:, :]) / m\n",
    "    sx = np.cov(v01)\n",
    "    sy = np.cov(v10)\n",
    "    delongcov = sx / m + sy / n\n",
    "    return aucs, delongcov\n",
    "\n",
    "\n",
    "def calc_pvalue(aucs, sigma):\n",
    "    \"\"\"Computes log(10) of p-values.\n",
    "    Args:\n",
    "       aucs: 1D array of AUCs\n",
    "       sigma: AUC DeLong covariances\n",
    "    Returns:\n",
    "       log10(pvalue)\n",
    "    \"\"\"\n",
    "    l = np.array([[1, -1]])\n",
    "    z = np.abs(np.diff(aucs)) / np.sqrt(np.dot(np.dot(l, sigma), l.T))\n",
    "    return np.log10(2) + scipy.stats.norm.logsf(z, loc=0, scale=1) / np.log(10)\n",
    "\n",
    "\n",
    "def compute_ground_truth_statistics(ground_truth):\n",
    "    assert np.array_equal(np.unique(ground_truth), [0, 1])\n",
    "    order = (-ground_truth).argsort()\n",
    "    label_1_count = int(ground_truth.sum())\n",
    "    return order, label_1_count\n",
    "\n",
    "\n",
    "def delong_roc_variance(ground_truth, predictions):\n",
    "    \"\"\"\n",
    "    Computes ROC AUC variance for a single set of predictions\n",
    "    Args:\n",
    "       ground_truth: np.array of 0 and 1\n",
    "       predictions: np.array of floats of the probability of being class 1\n",
    "    \"\"\"\n",
    "    order, label_1_count = compute_ground_truth_statistics(ground_truth)\n",
    "    predictions_sorted_transposed = predictions[np.newaxis, order]\n",
    "    aucs, delongcov = fastDeLong(predictions_sorted_transposed, label_1_count)\n",
    "    assert len(aucs) == 1, \"There is a bug in the code, please forward this to the developers\"\n",
    "    return aucs[0], delongcov\n",
    "\n",
    "\n",
    "def delong_roc_test(ground_truth, predictions_one, predictions_two):\n",
    "    \"\"\"\n",
    "    Computes log(p-value) for hypothesis that two ROC AUCs are different\n",
    "    Args:\n",
    "       ground_truth: np.array of 0 and 1\n",
    "       predictions_one: predictions of the first model,\n",
    "          np.array of floats of the probability of being class 1\n",
    "       predictions_two: predictions of the second model,\n",
    "          np.array of floats of the probability of being class 1\n",
    "    \"\"\"\n",
    "    order, label_1_count = compute_ground_truth_statistics(ground_truth)\n",
    "    predictions_sorted_transposed = np.vstack((predictions_one, predictions_two))[:, order]\n",
    "    aucs, delongcov = fastDeLong(predictions_sorted_transposed, label_1_count)\n",
    "    return calc_pvalue(aucs, delongcov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef0ad26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
